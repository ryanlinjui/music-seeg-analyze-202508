#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³æ¨‚èˆ‡SEEGä¿¡è™Ÿçš„Beatå’ŒBPMé—œä¿‚åˆ†ææ¨¡çµ„
"""

import numpy as np
import librosa
import matplotlib.pyplot as plt
import pandas as pd
import scipy.io
from scipy.signal import find_peaks, correlate, hilbert
from scipy.stats import pearsonr
from scipy.ndimage import gaussian_filter1d
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class BeatBPMAnalyzer:
    """Beatå’ŒBPMé—œä¿‚åˆ†æå™¨"""
    
    def __init__(self, fs=2048):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.fs = fs
        
        # å·²çŸ¥çš„éŸ³æ¨‚BPMä¿¡æ¯ï¼ˆå¾README.mdç²å–ï¼‰
        self.known_bpm = {
            'BrahmsPianoConcerto.wav': 93,
            'LostStars.wav': 82,
            'Doraemon.wav': 121
        }
    
    def analyze_beat_bpm_relationship(self, audio_data, seeg_data, song_name, channel_name):
        """
        èˆ‡main.pyæ¥å£å…¼å®¹çš„åˆ†ææ–¹æ³•
        åˆ†æéŸ³æ¨‚èˆ‡SEEGä¿¡è™Ÿçš„beatå’ŒBPMé—œä¿‚
        """
        print(f"ğŸµ é–‹å§‹åˆ†æ {song_name} - {channel_name} çš„Beat-BPMé—œä¿‚...")
        
        try:
            # é™åˆ¶æ•¸æ“šé•·åº¦é¿å…æº¢ä½ï¼ˆæœ€å¤š30ç§’ï¼‰
            max_samples = min(30 * self.fs, 60000)  # 30ç§’æˆ–æœ€å¤§60kæ¨£æœ¬
            min_length = min(len(audio_data), len(seeg_data), max_samples)
            
            audio_segment = audio_data[:min_length].astype(np.float32)
            seeg_segment = seeg_data[:min_length].astype(np.float32)
            
            # ç¢ºä¿seeg_dataæ˜¯1ç¶­æ•¸çµ„
            if seeg_segment.ndim > 1:
                seeg_segment = seeg_segment.flatten()
            
            print(f"   æ•¸æ“šé•·åº¦: {min_length} é» ({min_length/self.fs:.1f} ç§’)")
            
            # ç²å–å·²çŸ¥BPM
            known_bpm = None
            for key, bpm in self.known_bpm.items():
                if key.lower().replace('.wav', '') in song_name.lower():
                    known_bpm = bpm
                    break
            
            # 1. ä½¿ç”¨å·²çŸ¥BPMç”Ÿæˆbeatæ™‚é–“é»
            print("   ğŸ¼ ä½¿ç”¨å·²çŸ¥BPMç”Ÿæˆbeatæ™‚é–“é»...")
            music_result = self.generate_beats_from_known_bpm(audio_segment, self.fs, known_bpm)
            if not music_result:
                print("âŒ Beatæ™‚é–“é»ç”Ÿæˆå¤±æ•—")
                return None
            
            # 2. SEEG beatæª¢æ¸¬
            print("   ğŸ§  æª¢æ¸¬SEEG rhythm...")
            seeg_result = self.analyze_seeg_rhythm(seeg_segment)
            if not seeg_result:
                print("âŒ SEEGç¯€å¾‹æª¢æ¸¬å¤±æ•—")
                return None
            
            # 3. åŒæ­¥æ€§åˆ†æ
            print("   ğŸ”„ è¨ˆç®—åŒæ­¥æ€§...")
            sync_result = self.analyze_synchronization(audio_segment, seeg_segment)
            
            # 4. ç›¸é—œæ€§åˆ†æ
            print("   ğŸ“ˆ è¨ˆç®—ä¿¡è™Ÿç›¸é—œæ€§...")
            corr_analysis = self.analyze_correlation(audio_segment, seeg_segment, music_result['beat_times'])
            
            # 5. ç›¸ä½åŒæ­¥åˆ†æ
            print("   ğŸ“Š è¨ˆç®—ç›¸ä½åŒæ­¥...")
            phase_result = self.analyze_phase_synchronization(audio_segment, seeg_segment)
            if not phase_result:
                print("âŒ ç›¸ä½åŒæ­¥åˆ†æå¤±æ•—")
                return None
            
            # 6. è©³ç´°åŒæ­¥æ€§åˆ†æ
            print("   ğŸ”¬ é€²è¡Œç¶œåˆåˆ†æ...")
            sync_analysis = self.analyze_detailed_synchronization(audio_segment, seeg_segment, music_result['beat_times'])
            
            # 7. ç”Ÿæˆåˆ†ææ‘˜è¦
            summary = self.generate_analysis_summary(music_result, sync_result, sync_analysis, corr_analysis, phase_result)
            
            # 8. æ•´åˆæ‰€æœ‰çµæœ
            results = {
                'song_name': song_name,
                'channel_name': channel_name,
                'detected_bpm': float(known_bpm) if known_bpm else 0.0,
                'known_bpm': known_bpm,
                'bmp_accuracy': float(music_result['bmp_accuracy']),
                'beat_times': music_result['beat_times'],
                'beat_frequency': len(music_result['beat_times']) / (min_length / self.fs),
                'seeg_estimated_bpm': float(seeg_result['estimated_bpm']),
                'sync_score': float(sync_result['sync_score']),
                'best_lag': float(sync_result['best_lag']),
                'overall_correlation': float(corr_analysis['overall_correlation']),
                'mean_beat_correlation': float(corr_analysis['mean_beat_correlation']),
                'sliding_correlation': corr_analysis['sliding_correlation'],
                'sliding_times': corr_analysis['sliding_times'],
                'beat_correlations': corr_analysis['beat_correlations'],
                'phase_locking_value': float(phase_result['phase_locking_value']),
                'phase_consistency': float(phase_result['phase_consistency']),
                'beat_consistency_score': float(sync_analysis['beat_consistency_score']),
                'beat_enhancement': float(sync_analysis['beat_enhancement']),
                'analysis_summary': summary,
                'audio_signal': audio_segment,
                'seeg_signal': seeg_segment,
                'smooth_envelope': seeg_result['envelope'],
                'average_beat_response': sync_analysis['average_beat_response']
            }
            
            print(f"   âœ… åˆ†æå®Œæˆ")
            print(f"      ä½¿ç”¨BPM: {known_bpm}")
            print(f"      Beatæ•¸é‡: {len(music_result['beat_times'])}")
            print(f"      BPMæº–ç¢ºåº¦: {float(music_result['bmp_accuracy']):.1f}%")
            print(f"      æ•´é«”ç›¸é—œæ€§: {float(corr_analysis['overall_correlation']):.3f}")
            print(f"      ç¶œåˆè©•åˆ†: {float(summary['overall_synchronization_score']):.3f}")
            
            # 9. ç”Ÿæˆåˆ†æåœ–è¡¨
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            output_dir = Path("outputs")
            output_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜åœ–è¡¨
            fig_filename = f"beat_bpm_analysis_{song_name.replace(' ', '_')}_{channel_name}_{timestamp}.png"
            fig_path = output_dir / fig_filename
            fig = self.create_analysis_plots(results, fig_path)
            results['figure_path'] = fig_path
            
            # 10. ä¿å­˜CSVçµæœ
            csv_filename = f"beat_bpm_analysis_{song_name.replace(' ', '_')}_{channel_name}_{timestamp}.csv"
            csv_path = output_dir / csv_filename
            self.save_results_to_csv(results, csv_path)
            
            return results
            
        except Exception as e:
            print(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return None

    def generate_beats_from_known_bpm(self, audio_data, sr, known_bpm):
        """æ ¹æ“šå·²çŸ¥BPMç”Ÿæˆbeatæ™‚é–“é»"""
        try:
            if not known_bpm:
                print("âŒ æ²’æœ‰å·²çŸ¥BPMè³‡è¨Š")
                return None
            
            # è¨ˆç®—beaté–“éš”ï¼ˆç§’ï¼‰
            beat_interval = 60.0 / known_bpm
            audio_duration = len(audio_data) / sr
            
            # ç”Ÿæˆbeatæ™‚é–“é»ï¼ˆå¾0.5ç§’é–‹å§‹ï¼Œé¿å…é–‹é ­çš„éœéŸ³ï¼‰
            beat_times = []
            current_time = 0.5  # å¾0.5ç§’é–‹å§‹
            
            while current_time < audio_duration:
                beat_times.append(current_time)
                current_time += beat_interval
            
            beat_times = np.array(beat_times)
            
            # æº–ç¢ºåº¦è¨­ç‚º100%ï¼ˆå› ç‚ºä½¿ç”¨å·²çŸ¥BPMï¼‰
            bmp_accuracy = 100.0
            
            print(f"      æ ¹æ“šBPM {known_bpm}ç”Ÿæˆäº† {len(beat_times)} å€‹beat")
            print(f"      Beaté–“éš”: {beat_interval:.3f}ç§’")
            print(f"      éŸ³æ¨‚æ™‚é•·: {audio_duration:.1f}ç§’")
            
            return {
                'detected_bpm': known_bpm,
                'bmp_accuracy': bmp_accuracy,
                'beat_times': beat_times,
                'num_beats': len(beat_times)
            }
        except Exception as e:
            print(f"âŒ Beatç”Ÿæˆå¤±æ•—: {e}")
            return {
                'detected_bpm': 0.0,
                'bmp_accuracy': 0.0,
                'beat_times': np.array([]),
                'num_beats': 0
            }

    def analyze_seeg_rhythm(self, seeg_data):
        """åˆ†æSEEGä¿¡è™Ÿçš„ç¯€å¾‹ç‰¹å¾µ"""
        try:
            # é™åˆ¶æ•¸æ“šé•·åº¦ä»¥æé«˜æ•ˆç‡
            max_samples = min(len(seeg_data), 30000)  # æœ€å¤šåˆ†æ30kæ¨£æœ¬
            seeg_segment = seeg_data[:max_samples]
            
            # ç²å–ä¿¡è™ŸåŒ…çµ¡
            analytic_signal = hilbert(seeg_segment)
            envelope = np.abs(analytic_signal)
            
            # å¹³æ»‘åŒ…çµ¡
            sigma = min(5.0, len(envelope) / 2000)  # é©åº¦å¹³æ»‘
            smooth_envelope = gaussian_filter1d(envelope, sigma=sigma)
            
            # æª¢æ¸¬peaks - ä½¿ç”¨è¼ƒä½çš„é–¾å€¼ä»¥ç²å¾—æ›´å¤špeaks
            height_threshold = np.mean(smooth_envelope) + 0.5 * np.std(smooth_envelope)
            min_distance = max(10, int(self.fs * 0.1))  # æœ€å°é–“éš”0.1ç§’
            
            peaks, peak_properties = find_peaks(smooth_envelope, 
                                              height=height_threshold,
                                              distance=min_distance,
                                              prominence=0.1 * np.std(smooth_envelope))
            
            # ä¼°ç®—BPMï¼ˆåŸºæ–¼peaké–“éš”ï¼‰
            if len(peaks) > 3:  # éœ€è¦è¶³å¤ çš„peaksä¾†ä¼°ç®—
                peak_intervals = np.diff(peaks) / self.fs  # è½‰ç‚ºç§’
                # éæ¿¾ç•°å¸¸å€¼
                valid_intervals = peak_intervals[(peak_intervals > 0.3) & (peak_intervals < 3.0)]
                if len(valid_intervals) > 0:
                    mean_interval = np.median(valid_intervals)  # ä½¿ç”¨ä¸­ä½æ•¸æ›´ç©©å®š
                    estimated_bpm = 60.0 / mean_interval
                else:
                    estimated_bpm = 0.0
            else:
                estimated_bpm = 0.0
            
            # è¨ˆç®—ç¯€å¾‹å¼·åº¦
            rhythm_strength = np.std(smooth_envelope) / np.mean(smooth_envelope) if np.mean(smooth_envelope) > 0 else 0
            
            print(f"      æª¢æ¸¬åˆ° {len(peaks)} å€‹SEEG peaks")
            print(f"      ä¼°ç®—SEEG BPM: {estimated_bpm:.1f}")
            print(f"      ç¯€å¾‹å¼·åº¦: {rhythm_strength:.3f}")
            
            return {
                'estimated_bpm': estimated_bpm,
                'envelope': smooth_envelope,
                'peaks': peaks,
                'num_peaks': len(peaks),
                'rhythm_strength': rhythm_strength,
                'peak_heights': peak_properties.get('peak_heights', []) if hasattr(peak_properties, 'get') else []
            }
        except Exception as e:
            print(f"âŒ SEEGç¯€å¾‹åˆ†æå¤±æ•—: {e}")
            return {
                'estimated_bpm': 0.0,
                'envelope': np.zeros(min(len(seeg_data), 1000)),
                'peaks': np.array([]),
                'num_peaks': 0,
                'rhythm_strength': 0.0,
                'peak_heights': []
            }
            
    def analyze_synchronization(self, audio_data, seeg_data):
        """åˆ†æéŸ³æ¨‚èˆ‡SEEGä¿¡è™Ÿçš„åŒæ­¥æ€§"""
        try:
            # ç¢ºä¿æ•¸æ“šé•·åº¦ä¸€è‡´ä¸¦ä¸‹æ¡æ¨£
            min_length = min(len(audio_data), len(seeg_data), 20000)  # é™åˆ¶æœ€å¤§é•·åº¦
            audio_short = audio_data[:min_length]
            seeg_short = seeg_data[:min_length]
            
            # è¨ˆç®—äº’ç›¸é—œ
            correlation = correlate(audio_short, seeg_short, mode='full')
            lags = np.arange(-len(seeg_short) + 1, len(audio_short))
            
            # æ‰¾åˆ°æœ€å¤§ç›¸é—œå€¼å’Œå°æ‡‰çš„lag
            max_idx = np.argmax(np.abs(correlation))
            best_lag = lags[max_idx]
            max_correlation = correlation[max_idx]
            
            # è¨ˆç®—åŒæ­¥åˆ†æ•¸
            sync_score = float(np.abs(max_correlation) / (np.linalg.norm(audio_short) * np.linalg.norm(seeg_short)))
            
            return {
                'sync_score': sync_score,
                'best_lag': best_lag,
                'max_correlation': float(max_correlation)
            }
        except Exception as e:
            print(f"âŒ åŒæ­¥æ€§åˆ†æå¤±æ•—: {e}")
            return {
                'sync_score': 0.0,
                'best_lag': 0,
                'max_correlation': 0.0
            }

    def analyze_correlation(self, audio_data, seeg_data, beat_times):
        """åˆ†æéŸ³æ¨‚èˆ‡SEEGä¿¡è™Ÿçš„ç›¸é—œæ€§"""
        try:
            # ç¢ºä¿æ•¸æ“šé•·åº¦ä¸€è‡´
            min_length = min(len(audio_data), len(seeg_data))
            audio_aligned = audio_data[:min_length]
            seeg_aligned = seeg_data[:min_length]
            
            # æ•´é«”ç›¸é—œæ€§
            overall_corr, _ = pearsonr(audio_aligned, seeg_aligned)
            
            # æ»‘å‹•çª—å£ç›¸é—œæ€§åˆ†æ
            window_size = min(int(self.fs * 2), min_length // 10)  # 2ç§’çª—å£æˆ–æ•¸æ“šçš„1/10
            step_size = window_size // 2
            
            sliding_corr = []
            sliding_times = []
            
            for i in range(0, min_length - window_size, step_size):
                try:
                    window_audio = audio_aligned[i:i+window_size]
                    window_seeg = seeg_aligned[i:i+window_size]
                    corr, _ = pearsonr(window_audio, window_seeg)
                    sliding_corr.append(float(corr) if not np.isnan(corr) else 0.0)
                    sliding_times.append(i / self.fs)
                except:
                    sliding_corr.append(0.0)
                    sliding_times.append(i / self.fs)
            
            # Beatç›¸é—œçš„ç›¸é—œæ€§åˆ†æ
            beat_correlations = []
            beat_window = int(self.fs * 0.5)  # 0.5ç§’çª—å£
            
            for beat_time in beat_times:
                try:
                    beat_idx = int(beat_time * self.fs)
                    if beat_idx + beat_window < min_length:
                        audio_beat = audio_aligned[beat_idx:beat_idx+beat_window]
                        seeg_beat = seeg_aligned[beat_idx:beat_idx+beat_window]
                        corr, _ = pearsonr(audio_beat, seeg_beat)
                        beat_correlations.append(float(corr) if not np.isnan(corr) else 0.0)
                except:
                    beat_correlations.append(0.0)
            
            mean_beat_corr = np.mean(beat_correlations) if beat_correlations else 0.0
            
            return {
                'overall_correlation': float(overall_corr) if not np.isnan(overall_corr) else 0.0,
                'mean_beat_correlation': float(mean_beat_corr),
                'sliding_correlation': sliding_corr,
                'sliding_times': sliding_times,
                'beat_correlations': beat_correlations
            }
        except Exception as e:
            print(f"âŒ ç›¸é—œæ€§åˆ†æå¤±æ•—: {e}")
            return {
                'overall_correlation': 0.0,
                'mean_beat_correlation': 0.0,
                'sliding_correlation': [],
                'sliding_times': [],
                'beat_correlations': []
            }

    def analyze_phase_synchronization(self, audio_data, seeg_data):
        """åˆ†æç›¸ä½åŒæ­¥"""
        try:
            # ç¢ºä¿æ•¸æ“šé•·åº¦ä¸€è‡´ä¸¦é™åˆ¶é•·åº¦
            min_length = min(len(audio_data), len(seeg_data), 10000)
            audio_short = audio_data[:min_length]
            seeg_short = seeg_data[:min_length]
            
            # ç²å–ç¬æ™‚ç›¸ä½
            audio_analytic = hilbert(audio_short)
            seeg_analytic = hilbert(seeg_short)
            
            audio_phase = np.angle(audio_analytic)
            seeg_phase = np.angle(seeg_analytic)
            
            # è¨ˆç®—ç›¸ä½å·®
            phase_diff = audio_phase - seeg_phase
            
            # Phase Locking Value (PLV)
            plv = float(np.abs(np.mean(np.exp(1j * phase_diff))))
            
            # ç›¸ä½ä¸€è‡´æ€§
            phase_consistency = float(1 - np.std(np.angle(np.exp(1j * phase_diff))) / np.pi)
            
            return {
                'phase_locking_value': plv,
                'phase_consistency': phase_consistency,
                'phase_difference': phase_diff
            }
        except Exception as e:
            print(f"âŒ ç›¸ä½åŒæ­¥åˆ†æå¤±æ•—: {e}")
            return {
                'phase_locking_value': 0.0,
                'phase_consistency': 0.0,
                'phase_difference': np.array([])
            }

    def analyze_detailed_synchronization(self, audio_data, seeg_data, beat_times):
        """è©³ç´°åŒæ­¥æ€§åˆ†æ"""
        try:
            # ç¢ºä¿æ•¸æ“šé•·åº¦ä¸€è‡´
            min_length = min(len(audio_data), len(seeg_data))
            audio_aligned = audio_data[:min_length]
            seeg_aligned = seeg_data[:min_length]
            
            # Beatä¸€è‡´æ€§åˆ†æ
            beat_responses = []
            beat_window = int(self.fs * 0.5)  # 0.5ç§’çª—å£
            
            for beat_time in beat_times:
                try:
                    beat_idx = int(beat_time * self.fs)
                    if beat_idx + beat_window < min_length:
                        seeg_beat = seeg_aligned[beat_idx:beat_idx+beat_window]
                        beat_responses.append(seeg_beat)
                except:
                    continue
            
            if beat_responses:
                # ç¢ºä¿æ‰€æœ‰beatéŸ¿æ‡‰é•·åº¦ä¸€è‡´
                min_beat_length = min(len(br) for br in beat_responses)
                beat_responses = [br[:min_beat_length] for br in beat_responses]
                
                # è¨ˆç®—å¹³å‡beatéŸ¿æ‡‰
                average_beat_response = np.mean(beat_responses, axis=0)
                
                # Beatä¸€è‡´æ€§åˆ†æ•¸
                consistencies = []
                for br in beat_responses:
                    try:
                        corr, _ = pearsonr(br, average_beat_response)
                        consistencies.append(float(corr) if not np.isnan(corr) else 0.0)
                    except:
                        consistencies.append(0.0)
                
                beat_consistency_score = float(np.mean(consistencies))
                
                # Beatå¢å¼·ç¨‹åº¦
                baseline_var = np.var(seeg_aligned)
                beat_var = np.var(average_beat_response)
                beat_enhancement = float(beat_var / baseline_var) if baseline_var > 0 else 0.0
            else:
                average_beat_response = np.array([])
                beat_consistency_score = 0.0
                beat_enhancement = 0.0
            
            return {
                'beat_consistency_score': beat_consistency_score,
                'beat_enhancement': beat_enhancement,
                'average_beat_response': average_beat_response,
                'num_beats_analyzed': len(beat_responses)
            }
        except Exception as e:
            print(f"âŒ è©³ç´°åŒæ­¥æ€§åˆ†æå¤±æ•—: {e}")
            return {
                'beat_consistency_score': 0.0,
                'beat_enhancement': 0.0,
                'average_beat_response': np.array([]),
                'num_beats_analyzed': 0
            }

    def generate_analysis_summary(self, music_result, sync_result, sync_analysis, corr_analysis, phase_result):
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        try:
            # ç¶œåˆè©•åˆ†è¨ˆç®—
            scores = [
                float(music_result['bmp_accuracy']) / 100.0,
                float(sync_result['sync_score']),
                float(abs(corr_analysis['overall_correlation'])),
                float(corr_analysis['mean_beat_correlation']),
                float(phase_result['phase_locking_value']),
                float(sync_analysis['beat_consistency_score'])
            ]
            
            # éæ¿¾æ‰NaNå€¼
            valid_scores = [s for s in scores if not np.isnan(s)]
            overall_score = float(np.mean(valid_scores)) if valid_scores else 0.0
            
            # å“è³ªè©•ç´š
            if overall_score >= 0.7:
                quality_grade = "å„ªç§€"
            elif overall_score >= 0.5:
                quality_grade = "è‰¯å¥½"
            elif overall_score >= 0.3:
                quality_grade = "ä¸€èˆ¬"
            else:
                quality_grade = "è¼ƒå·®"
            
            return {
                'overall_synchronization_score': overall_score,
                'quality_grade': quality_grade,
                'bmp_detection_quality': "æº–ç¢º" if float(music_result['bmp_accuracy']) > 90 else "ä¸€èˆ¬",
                'sync_quality': "é«˜" if float(sync_result['sync_score']) > 0.5 else "ä¸­ç­‰",
                'correlation_strength': "å¼·" if float(abs(corr_analysis['overall_correlation'])) > 0.5 else "ä¸­ç­‰"
            }
        except Exception as e:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}")
            return {
                'overall_synchronization_score': 0.0,
                'quality_grade': "æœªçŸ¥",
                'bmp_detection_quality': "æœªçŸ¥",
                'sync_quality': "æœªçŸ¥",
                'correlation_strength': "æœªçŸ¥"
            }

    def create_analysis_plots(self, results, save_path):
        """å‰µå»ºåˆ†æåœ–è¡¨"""
        try:
            # è¨­ç½®ä¸­æ–‡å­—é«”
            plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            fig, axes = plt.subplots(3, 2, figsize=(15, 12))
            fig.suptitle(f"Beat-BPM åˆ†æå ±å‘Š: {results['song_name']} - {results['channel_name']}", 
                        fontsize=16, fontweight='bold')
            
            # é™åˆ¶é¡¯ç¤ºé•·åº¦ï¼ˆå‰30ç§’ï¼‰
            max_display_samples = min(30 * self.fs, len(results['audio_signal']))
            time_axis = np.arange(max_display_samples) / self.fs
            
            # 1. éŸ³æ¨‚ä¿¡è™Ÿèˆ‡beatæ¨™è¨˜
            axes[0,0].plot(time_axis, results['audio_signal'][:max_display_samples], 'b-', alpha=0.7, label='éŸ³æ¨‚ä¿¡è™Ÿ')
            for bt in results['beat_times']:
                if bt <= 30:  # åªé¡¯ç¤ºå‰30ç§’çš„beat
                    axes[0,0].axvline(x=bt, color='r', linestyle='--', alpha=0.8)
            axes[0,0].set_title(f'éŸ³æ¨‚ä¿¡è™Ÿèˆ‡Beatæ¨™è¨˜\nä½¿ç”¨BPM: {results["known_bpm"]} | Beatæ•¸: {len(results["beat_times"])}')
            axes[0,0].set_xlabel('æ™‚é–“ (ç§’)')
            axes[0,0].set_ylabel('æŒ¯å¹…')
            axes[0,0].grid(True, alpha=0.3)
            axes[0,0].legend()
            
            # 2. SEEGä¿¡è™Ÿèˆ‡åŒ…çµ¡
            axes[0,1].plot(time_axis, results['seeg_signal'][:max_display_samples], 'g-', alpha=0.7, label='SEEGä¿¡è™Ÿ')
            if len(results['smooth_envelope']) == len(results['seeg_signal']):
                axes[0,1].plot(time_axis, results['smooth_envelope'][:max_display_samples], 'r-', linewidth=2, label='å¹³æ»‘åŒ…çµ¡')
            axes[0,1].set_title(f'SEEGä¿¡è™Ÿèˆ‡åŒ…çµ¡\nä¼°ç®—BPM: {float(results["seeg_estimated_bpm"]):.1f}')
            axes[0,1].set_xlabel('æ™‚é–“ (ç§’)')
            axes[0,1].set_ylabel('æŒ¯å¹…')
            axes[0,1].grid(True, alpha=0.3)
            axes[0,1].legend()
            
            # 3. æ»‘å‹•ç›¸é—œæ€§
            if results['sliding_times']:
                axes[1,0].plot(results['sliding_times'], results['sliding_correlation'], 'purple', linewidth=2)
                axes[1,0].set_title(f'æ»‘å‹•çª—å£ç›¸é—œæ€§\næ•´é«”ç›¸é—œæ€§: {float(results["overall_correlation"]):.3f}')
                axes[1,0].set_xlabel('æ™‚é–“ (ç§’)')
                axes[1,0].set_ylabel('ç›¸é—œä¿‚æ•¸')
                axes[1,0].grid(True, alpha=0.3)
                axes[1,0].axhline(y=0, color='k', linestyle='-', alpha=0.3)
            
            # 4. Beatç›¸é—œæ€§åˆ†ä½ˆ
            if results['beat_correlations']:
                axes[1,1].hist(results['beat_correlations'], bins=20, alpha=0.7, color='orange', edgecolor='black')
                axes[1,1].set_title(f'Beatç›¸é—œæ€§åˆ†ä½ˆ\nå¹³å‡: {float(results["mean_beat_correlation"]):.3f}')
                axes[1,1].set_xlabel('ç›¸é—œä¿‚æ•¸')
                axes[1,1].set_ylabel('é »æ•¸')
                axes[1,1].grid(True, alpha=0.3)
            
            # 5. ç›¸ä½åŒæ­¥æŒ‡æ¨™
            metrics = ['BPMæº–ç¢ºåº¦', 'åŒæ­¥åˆ†æ•¸', 'æ•´é«”ç›¸é—œæ€§', 'Beatç›¸é—œæ€§', 'ç›¸ä½é–å®š', 'Beatä¸€è‡´æ€§']
            values = [
                float(results['bmp_accuracy']) / 100,
                float(results['sync_score']),
                float(abs(results['overall_correlation'])),
                float(abs(results['mean_beat_correlation'])),
                float(results['phase_locking_value']),
                float(results['beat_consistency_score'])
            ]
            
            bars = axes[2,0].bar(range(len(metrics)), values, color=['red', 'blue', 'green', 'orange', 'purple', 'brown'])
            axes[2,0].set_title('ç¶œåˆåŒæ­¥æ€§æŒ‡æ¨™')
            axes[2,0].set_xlabel('æŒ‡æ¨™')
            axes[2,0].set_ylabel('åˆ†æ•¸')
            axes[2,0].set_xticks(range(len(metrics)))
            axes[2,0].set_xticklabels(metrics, rotation=45, ha='right')
            axes[2,0].set_ylim(0, 1)
            axes[2,0].grid(True, alpha=0.3)
            
            # åœ¨æŸ±ç‹€åœ–ä¸Šæ·»åŠ æ•¸å€¼
            for bar, value in zip(bars, values):
                height = bar.get_height()
                axes[2,0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                             f'{value:.3f}', ha='center', va='bottom', fontsize=8)
            
            # 6. åˆ†ææ‘˜è¦
            summary_text = f"""
åˆ†ææ‘˜è¦:
â€¢ ç¶œåˆè©•åˆ†: {float(results['analysis_summary']['overall_synchronization_score']):.3f}
â€¢ å“è³ªç­‰ç´š: {results['analysis_summary']['quality_grade']}
â€¢ BPMæª¢æ¸¬: {results['analysis_summary']['bmp_detection_quality']}
â€¢ åŒæ­¥å“è³ª: {results['analysis_summary']['sync_quality']}
â€¢ ç›¸é—œå¼·åº¦: {results['analysis_summary']['correlation_strength']}

æ•¸æ“šçµ±è¨ˆ:
â€¢ æª¢æ¸¬åˆ° {len(results['beat_times'])} å€‹beats
â€¢ ç›¸ä½é–å®šå€¼: {float(results['phase_locking_value']):.3f}
â€¢ Beatå¢å¼·ç¨‹åº¦: {float(results['beat_enhancement']):.3f}
â€¢ æœ€ä½³å»¶é²: {float(results['best_lag']):.1f} æ¨£æœ¬
            """
            
            axes[2,1].text(0.05, 0.95, summary_text, transform=axes[2,1].transAxes, 
                          fontsize=10, verticalalignment='top', fontfamily='monospace',
                          bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
            axes[2,1].set_xlim(0, 1)
            axes[2,1].set_ylim(0, 1)
            axes[2,1].axis('off')
            
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"   ğŸ“Š åˆ†æåœ–è¡¨å·²ä¿å­˜: {save_path}")
            return fig
            
        except Exception as e:
            print(f"âŒ åœ–è¡¨ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return None

    def save_results_to_csv(self, results, save_path):
        """ä¿å­˜åˆ†æçµæœåˆ°CSVæ–‡ä»¶"""
        try:
            # æº–å‚™CSVæ•¸æ“š
            csv_data = {
                'æ­Œæ›²åç¨±': [results['song_name']],
                'é›»æ¥µé€šé“': [results['channel_name']],
                'ä½¿ç”¨BPM': [results['known_bpm']],
                'Beatæ•¸é‡': [len(results['beat_times'])],
                'Beaté »ç‡(Hz)': [float(results['beat_frequency'])],
                'SEEGä¼°ç®—BPM': [float(results['seeg_estimated_bpm'])],
                'åŒæ­¥åˆ†æ•¸': [float(results['sync_score'])],
                'æœ€ä½³å»¶é²(æ¨£æœ¬)': [float(results['best_lag'])],
                'æ•´é«”ç›¸é—œæ€§': [float(results['overall_correlation'])],
                'å¹³å‡Beatç›¸é—œæ€§': [float(results['mean_beat_correlation'])],
                'æ»‘å‹•ç›¸é—œæ€§æ•¸é‡': [len(results['sliding_correlation'])],
                'Beatç›¸é—œæ€§æ•¸é‡': [len(results['beat_correlations'])],
                'ç›¸ä½é–å®šå€¼': [float(results['phase_locking_value'])],
                'ç›¸ä½ä¸€è‡´æ€§': [float(results['phase_consistency'])],
                'Beatä¸€è‡´æ€§åˆ†æ•¸': [float(results['beat_consistency_score'])],
                'Beatå¢å¼·ç¨‹åº¦': [float(results['beat_enhancement'])],
                'ç¶œåˆè©•åˆ†': [float(results['analysis_summary']['overall_synchronization_score'])],
                'å“è³ªç­‰ç´š': [results['analysis_summary']['quality_grade']],
                'BPMæª¢æ¸¬å“è³ª': [results['analysis_summary']['bmp_detection_quality']],
                'åŒæ­¥å“è³ª': [results['analysis_summary']['sync_quality']],
                'ç›¸é—œå¼·åº¦': [results['analysis_summary']['correlation_strength']],
                'åˆ†ææ•¸æ“šé•·åº¦(ç§’)': [len(results['audio_signal']) / self.fs],
                'åˆ†ææ™‚é–“': [pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')]
            }
            
            df = pd.DataFrame(csv_data)
            df.to_csv(save_path, index=False, encoding='utf-8-sig')
            
            print(f"   ğŸ’¾ åˆ†æçµæœå·²ä¿å­˜: {save_path}")
            
        except Exception as e:
            print(f"âŒ CSVä¿å­˜å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
